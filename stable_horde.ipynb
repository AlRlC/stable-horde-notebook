{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/JJmqJSG7pdUEfRAjB+Of"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9Yrgnqzk2Wou"
      },
      "outputs": [],
      "source": [
        "#@markdown # Download repo\n",
        "!git clone https://github.com/sd-webui/nataili.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json, requests, time, os\n",
        "from IPython.display import clear_output\n",
        "\n",
        "#@markdown # Model Download/Load\n",
        "token = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Or\n",
        "Path_to_trained_model = \"\" #@param {type:\"string\"}\n",
        "#@markdown Insert the full path of your trained model (eg: /content/gdrive/MyDrive/zarathustra.ckpt) and it will automatically be placed in the right place, otherwise, leave it EMPTY (make sure there are no spaces in the path)\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "stable_diffusion_v1_5 = True #@param {type:\"boolean\"}\n",
        "#@markdown * Generalist AI image generating model. The baseline for all finetuned models.\n",
        "stable_diffusion_v1_4 = False #@param {type:\"boolean\"}\n",
        "#@markdown * Old version. Generalist AI image generating model. The baseline for all finetuned models.\n",
        "waifu_diffusion = False #@param {type:\"boolean\"}\n",
        "#@markdown * Anime styled generations.\n",
        "furry_epoch = False #@param {type:\"boolean\"}\n",
        "#@markdown * Furry styled generations.\n",
        "yiffy = False #@param {type:\"boolean\"}\n",
        "#@markdown * Furry styled generations.\n",
        "Zack3D = False #@param {type:\"boolean\"}\n",
        "#@markdown * Kink/NSFW oriented furry styled generations.\n",
        "trinart = False #@param {type:\"boolean\"}\n",
        "#@markdown * SFW Manga styled generations.\n",
        "\n",
        "!mkdir -p /content/nataili/models/custom/\n",
        "!mkdir -p /content/nataili/models/ldm/stable-diffusion-v1/\n",
        "\n",
        "models = json.load(open('/content/nataili/db.json'))\n",
        "dependencies = json.load(open('/content/nataili/db_dep.json'))\n",
        "remote_models = \"https://raw.githubusercontent.com/db0/nataili-model-reference/main/db.json\"\n",
        "remote_dependencies = \"https://raw.githubusercontent.com/db0/nataili-model-reference/main/db_dep.json\"\n",
        "try:\n",
        "  r = requests.get(remote_models)\n",
        "  models = r.json()\n",
        "  r = requests.get(remote_dependencies)\n",
        "  dependencies = dependencies\n",
        "except:\n",
        "  models = models\n",
        "  dependencies = dependencies\n",
        "\n",
        "def download_model(name):\n",
        "  if not name in models:\n",
        "    print(\"Model not found!\")\n",
        "  model = models[name]\n",
        "  download = model[\"config\"][\"download\"][0]\n",
        "\n",
        "  if 'file_url' in download:\n",
        "    download_url = download['file_url']\n",
        "    link = download_url.split(\"/\")\n",
        "    file_name = link[len(link) - 1]\n",
        "    if 'hf_auth' in download:\n",
        "      download_url = download_url.format(username=\"USER\", password=token)\n",
        "\n",
        "  if token == \"\" and \"hf_auth\" in download:\n",
        "    print('Huggingface token not supplied!')\n",
        "    exit()\n",
        "\n",
        "  model_destination = \"/content/nataili/\" + model[\"config\"][\"files\"][0][\"path\"]\n",
        "\n",
        "  !wget -O $model_destination $download_url\n",
        "  print(\"Downloaded model:\", name)\n",
        "\n",
        "if stable_diffusion_v1_5:\n",
        "  download_model(\"stable_diffusion\")\n",
        "if stable_diffusion_v1_4:\n",
        "  download_model(\"stable_diffusion_1.4\")\n",
        "if waifu_diffusion:\n",
        "  download_model(\"waifu_diffusion\")\n",
        "if furry_epoch:\n",
        "  download_model(\"waifu_diffusion\")\n",
        "if yiffy:\n",
        "  download_model(\"Yiffy\")\n",
        "if Zack3D:\n",
        "  download_model(\"Zack3D\")\n",
        "if trinart:\n",
        "  download_model(\"trinart\")\n",
        "\n",
        "if Path_to_trained_model != '':\n",
        "    if os.path.exists(str(Path_to_trained_model)):\n",
        "        clear_output()\n",
        "        !cp $Path_to_trained_model $required_path\n",
        "        if os.path.exists(required_path):\n",
        "            print('Model placed in the right directory')\n",
        "        else:\n",
        "            print('Something went wrong')\n",
        "    else:\n",
        "        print('Wrong path, use the colab file explorer to copy the path')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "sNOS6COYUQAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Download dependencies (run again if there's an error)\n",
        "%cd /content/nataili/\n",
        "!wget -qO- https://micromamba.snakepit.net/api/micromamba/linux-64/latest | tar -xvj bin/micromamba\n",
        "!bin/micromamba create --no-shortcuts -r conda -n linux -f environment.yaml -y"
      ],
      "metadata": {
        "cellView": "form",
        "id": "8Mp9h05m6UBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting worker info\n",
        "1. Rename `bridgeData_template.py` to `bridgeData.py`. \n",
        "2. Edit `bridgeData.py` and enter details such as the `horde_name` and `horde_api_key` you've received, so that you can receive Kudos.\n",
        "3. If you downloaded extra models other than 1.5, list it in `models_to_load`.\n",
        "**Note**: If you do not do this step, you will contribute anonymously."
      ],
      "metadata": {
        "id": "L4IfSgUTeNHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Start Stable Horde worker\n",
        "%cd /content/nataili/\n",
        "!bin/micromamba run -r conda -n linux python bridge.py $*"
      ],
      "metadata": {
        "cellView": "form",
        "id": "MUosNcNE3TPy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}