{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Use Google Drive (optional)\n",
        "#@markdown Models will be saved and loaded from your Google Drive.\n",
        "from google.colab import drive\n",
        "mount_google_drive = True\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "3qk09L_2q6J6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9Yrgnqzk2Wou"
      },
      "outputs": [],
      "source": [
        "#@markdown # Download repo\n",
        "update_repo = False #@param {type:\"boolean\"}\n",
        "\n",
        "if not \"mount_google_drive\" in locals():\n",
        "  mount_google_drive = False\n",
        "\n",
        "if mount_google_drive:\n",
        "  %cd /content/gdrive/MyDrive/\n",
        "else:\n",
        "  %cd /content/\n",
        "\n",
        "if update_repo:\n",
        "  %cd nataili/\n",
        "  !git pull\n",
        "else:\n",
        "  !git clone https://github.com/sd-webui/nataili.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json, requests, time, os\n",
        "from google.colab import drive\n",
        "from IPython.display import clear_output\n",
        "\n",
        "if not \"mount_google_drive\" in locals():\n",
        "  mount_google_drive = False\n",
        "\n",
        "#@markdown # Model Download/Load\n",
        "token = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Or\n",
        "Path_to_trained_model = \"\" #@param {type:\"string\"}\n",
        "#@markdown Insert the full path of your trained model (eg: /content/gdrive/MyDrive/zarathustra.ckpt) and it will automatically be placed in the right place, otherwise, leave it EMPTY (make sure there are no spaces in the path)\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "stable_diffusion_v1_5 = True #@param {type:\"boolean\"}\n",
        "#@markdown * Generalist AI image generating model. The baseline for all finetuned models.\n",
        "stable_diffusion_v1_4 = False #@param {type:\"boolean\"}\n",
        "#@markdown * Old version. Generalist AI image generating model. The baseline for all finetuned models.\n",
        "waifu_diffusion = False #@param {type:\"boolean\"}\n",
        "#@markdown * Anime styled generations.\n",
        "furry_epoch = False #@param {type:\"boolean\"}\n",
        "#@markdown * Furry styled generations.\n",
        "yiffy = False #@param {type:\"boolean\"}\n",
        "#@markdown * Furry styled generations.\n",
        "Zack3D = False #@param {type:\"boolean\"}\n",
        "#@markdown * Kink/NSFW oriented furry styled generations.\n",
        "trinart = False #@param {type:\"boolean\"}\n",
        "#@markdown * SFW Manga styled generations.\n",
        "colorbook = False #@param {type:\"boolean\"}\n",
        "#@markdown * Minimalist coloring book style images.\n",
        "arcane_diffusion = False #@param {type:\"boolean\"}\n",
        "#@markdown * Based on the Arcane TV show.\n",
        "spiderverse_diffusion = False #@param {type:\"boolean\"}\n",
        "#@markdown * Based on the Into the Spider-Verse movie's animation style.\n",
        "archer_diffusion = False #@param {type:\"boolean\"}\n",
        "#@markdown * Based on the Archer's TV show animation style.\n",
        "elden_ring_diffusion = False #@param {type:\"boolean\"}\n",
        "#@markdown * Based on the Elden Ring video game style.\n",
        "robo_diffusion = False #@param {type:\"boolean\"}\n",
        "#@markdown * Robot oriented drawing style.\n",
        "\n",
        "if mount_google_drive:\n",
        "  %cd /content/gdrive/MyDrive/nataili/\n",
        "else:\n",
        "  %cd /content/nataili/\n",
        "\n",
        "!mkdir -p models/custom/\n",
        "!mkdir -p models/ldm/stable-diffusion-v1/\n",
        "\n",
        "models = json.load(open('./db.json'))\n",
        "dependencies = json.load(open('./db_dep.json'))\n",
        "remote_models = \"https://raw.githubusercontent.com/db0/nataili-model-reference/main/db.json\"\n",
        "remote_dependencies = \"https://raw.githubusercontent.com/db0/nataili-model-reference/main/db_dep.json\"\n",
        "try:\n",
        "  r = requests.get(remote_models)\n",
        "  models = r.json()\n",
        "  r = requests.get(remote_dependencies)\n",
        "  dependencies = dependencies\n",
        "except:\n",
        "  models = models\n",
        "  dependencies = dependencies\n",
        "\n",
        "def download_model(name):\n",
        "  if not name in models:\n",
        "    print(\"Model not found!\")\n",
        "\n",
        "  model = models[name]\n",
        "  download = model[\"config\"][\"download\"][0]\n",
        "\n",
        "  if 'file_url' in download:\n",
        "    download_url = download['file_url']\n",
        "    link = download_url.split(\"/\")\n",
        "    file_name = link[len(link) - 1]\n",
        "    if 'hf_auth' in download:\n",
        "      download_url = download_url.format(username=\"USER\", password=token)\n",
        "\n",
        "  if token == \"\" and \"hf_auth\" in download:\n",
        "    print('Huggingface token not supplied!')\n",
        "    exit()\n",
        "\n",
        "  model_destination = model[\"config\"][\"files\"][0][\"path\"]\n",
        "\n",
        "  !wget -O $model_destination $download_url\n",
        "  print(\"Downloaded model:\", name)\n",
        "\n",
        "if stable_diffusion_v1_5:\n",
        "  download_model(\"stable_diffusion\")\n",
        "if stable_diffusion_v1_4:\n",
        "  download_model(\"stable_diffusion_1.4\")\n",
        "if waifu_diffusion:\n",
        "  download_model(\"waifu_diffusion\")\n",
        "if furry_epoch:\n",
        "  download_model(\"Furry Epoch\")\n",
        "if yiffy:\n",
        "  download_model(\"Yiffy\")\n",
        "if Zack3D:\n",
        "  download_model(\"Zack3D\")\n",
        "if trinart:\n",
        "  download_model(\"trinart\")\n",
        "if colorbook:\n",
        "  download_model(\"colorbook\")\n",
        "if arcane_diffusion:\n",
        "  download_model(\"Arcane Diffusion\")\n",
        "if spiderverse_diffusion:\n",
        "  download_model(\"Spider-Verse Diffusion\")\n",
        "if archer_diffusion:\n",
        "  download_model(\"Archer Diffusion\")\n",
        "if elden_ring_diffusion:\n",
        "  download_model(\"Elden Ring Diffusion\")\n",
        "if robo_diffusion:\n",
        "  download_model(\"Robo-Diffusion\")\n",
        "\n",
        "if Path_to_trained_model != '':\n",
        "    if os.path.exists(str(Path_to_trained_model)):\n",
        "        clear_output()\n",
        "        !cp $Path_to_trained_model $required_path\n",
        "        if os.path.exists(required_path):\n",
        "            print('Model placed in the right directory')\n",
        "        else:\n",
        "            print('Something went wrong')\n",
        "    else:\n",
        "        print('Wrong path, use the colab file explorer to copy the path')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "sNOS6COYUQAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Install Python 3.8\n",
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.8\n",
        "\n",
        "#change alternatives\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.7 1\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 2\n",
        "\n",
        "#check python version\n",
        "!python --version\n",
        "\n",
        "# Install pip\n",
        "!sudo apt install python3-pip\n",
        "!python -m pip install --upgrade pip"
      ],
      "metadata": {
        "cellView": "form",
        "id": "U9H99XmOZ6Qu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Install dependencies\n",
        "\n",
        "if not \"mount_google_drive\" in locals():\n",
        "  mount_google_drive = False\n",
        "\n",
        "if mount_google_drive:\n",
        "  %cd /content/gdrive/MyDrive/nataili/\n",
        "else:\n",
        "  %cd /content/nataili\n",
        "\n",
        "!pip install -e .\n",
        "\n",
        "!pip install ray\n",
        "\n",
        "# See: https://github.com/CompVis/taming-transformers/issues/176\n",
        "# do not uncomment -e git+https://github.com/CompVis/taming-transformers.git@master#egg=taming-transformers\n",
        "!pip install invisible-watermark==0.1.5\n",
        "!pip install taming-transformers-rom1504==0.0.6  # required by ldm\n",
        "\n",
        "!pip install git+https://github.com/crowsonkb/k-diffusion.git\n",
        "\n",
        "# Dependencies required for Stable Diffusion UI\n",
        "!pip install pynvml==11.4.1\n",
        "!pip install omegaconf==2.2.3\n",
        "\n",
        "# Note: Jinja2 3.x major version required due to breaking changes found in markupsafe==2.1.1; 2.0.1 is incompatible with other upstream dependencies\n",
        "# see https://github.com/pallets/markupsafe/issues/304\n",
        "!pip install Jinja2==3.1.2  # Jinja2 is required by Gradio\n",
        "\n",
        "#!pip install diffusers==0.4.1\n",
        "!pip install diffusers==0.6.0\n",
        "\n",
        "# Img2text\n",
        "!pip install fairscale==0.4.4\n",
        "!pip install timm==0.6.7\n",
        "!pip install tqdm==4.64.0\n",
        "\n",
        "# Other\n",
        "!pip install retry==0.9.2  # used by sd_utils\n",
        "!pip install python-slugify==6.1.2  # used by sd_utils\n",
        "!pip install piexif==1.1.3  # used by sd_utils\n",
        "\n",
        "!pip install accelerate==0.12.0\n",
        "!pip install albumentations==0.4.3\n",
        "!pip install einops==0.3.1\n",
        "!pip install facexlib>=0.2.3\n",
        "!pip install imageio-ffmpeg==0.4.2\n",
        "!pip install imageio==2.9.0\n",
        "!pip install kornia==0.6\n",
        "!pip install loguru\n",
        "!pip install opencv-python-headless==4.6.0.66\n",
        "!pip install open-clip-torch==2.0.2\n",
        "!pip install pandas==1.4.3\n",
        "!pip install pudb==2019.2\n",
        "!pip install pytorch-lightning==1.7.7\n",
        "!pip install realesrgan==0.3.0\n",
        "!pip install test-tube>=0.7.5\n",
        "!pip install timm==0.6.7\n",
        "!pip install torch-fidelity==0.3.0\n",
        "#!pip install transformers==4.19.2 # do not change\n",
        "!pip install transformers\n",
        "!pip install wget\n",
        "\n",
        "# Upscalers\n",
        "!pip install basicsr==1.4.2  # required by RealESRGAN\n",
        "!pip install gfpgan==1.3.8  # GFPGAN\n",
        "!pip install realesrgan==0.3.0  # RealESRGAN brings in GFPGAN as a requirement\n",
        "!pip install git+https://github.com/CompVis/latent-diffusion\n",
        "\n",
        "## for monocular depth estimation \n",
        "!pip install tensorflow==2.10.0\n",
        "\n",
        "## xformers\n",
        "#!pip install xformers-0.0.14.dev0-cp38-cp38-linux_x86_64.whl"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Dk7dKkA3bKWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting worker info\n",
        "1. Rename `bridgeData_template.py` to `bridgeData.py`. \n",
        "2. Edit `bridgeData.py` and enter details such as the `horde_name` and `horde_api_key` you've received, so that you can receive Kudos.\n",
        "3. If you downloaded extra models other than 1.5, list it in `models_to_load`.\n",
        "\n",
        "OR\n",
        "\n",
        "1. Fill and run the cell bellow.\n",
        "\n",
        "**Note**: If you do not do this step, you will contribute anonymously."
      ],
      "metadata": {
        "id": "L4IfSgUTeNHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The horde url\n",
        "horde_url = \"https://stablehorde.net\"\n",
        "# Give a cool name to your instance\n",
        "worker_name = \"My Awesome Instance\"\n",
        "# The api_key identifies a unique user in the horde\n",
        "# Visit https://stablehorde.net/register to create one before you can join\n",
        "api_key = \"0000000000\"\n",
        "# Put other users whose prompts you want to prioritize.\n",
        "# The owner's username is always included so you don't need to add it here, unless you want it to have lower priority than another user\n",
        "priority_usernames = []\n",
        "# The amount of power your system can handle\n",
        "# 8 means 512*512. Each increase increases the possible resoluion by 64 pixes\n",
        "# So if you put this to 2 (the minimum, your SD can only generate 64x64 pixels\n",
        "# If you put this to 32, it is equivalent to 1024x1024 pixels\n",
        "max_power = 8\n",
        "# Set this to false, if you do not want your worker to receive requests for NSFW generations\n",
        "nsfw = True\n",
        "# Set this to True if you want your worker to censor NSFW generations. This will only be active is horde_nsfw == False\n",
        "censor_nsfw = False\n",
        "# A list of words which you do not want to your worker to accept\n",
        "blacklist = []\n",
        "# A list of words for which you always want to allow the NSFW censor filter, even when this worker is in NSFW mode\n",
        "censorlist = []\n",
        "# If set to False, this worker will no longer pick img2img jobs\n",
        "allow_img2img = True\n",
        "# If set to False, this worker will no longer pick img2img jobs from unsafe IPs\n",
        "allow_unsafe_ip = True\n",
        "# The models to use. You can select a different main model, or select more than one if you have enough VRAM\n",
        "# The last model in this list takes priority when the client accepts more than 1\n",
        "# if you do not know which models you can add here, use the below command\n",
        "# python show_available_models.py\n",
        "models_to_load = [\n",
        "    \"stable_diffusion\"\n",
        "    # \"trinart\"\n",
        "    # \"Furry Epoch\"\n",
        "    # \"waifu_diffusion\"\n",
        "]"
      ],
      "metadata": {
        "id": "LfULY3uOREQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Start Stable Horde worker\n",
        "import os\n",
        "\n",
        "if not \"mount_google_drive\" in locals():\n",
        "  mount_google_drive = False\n",
        "\n",
        "if \"api_key\" in locals():\n",
        "  os.environ[\"HORDE_URL\"] = horde_url\n",
        "  os.environ[\"HORDE_WORKER_NAME\"] = worker_name\n",
        "  os.environ[\"HORDE_API_KEY\"] = api_key\n",
        "  os.environ[\"HORDE_PRIORITY_USERNAMES\"] = \",\".join(priority_usernames)\n",
        "  os.environ[\"HORDE_MAX_POWER\"] = str(max_power)\n",
        "  os.environ[\"HORDE_NSFW\"] = \"true\" if nsfw else \"false\"\n",
        "  os.environ[\"HORDE_CENSOR\"] = \"true\" if censor_nsfw else \"false\"\n",
        "  os.environ[\"HORDE_BLACKLIST\"] = \"true\" if censor_nsfw else \"false\"\n",
        "  os.environ[\"HORDE_CENSORLIST\"] = \",\".join(censorlist)\n",
        "  os.environ[\"HORDE_IMG2IMG\"] = \"true\" if allow_img2img else \"false\"\n",
        "  os.environ[\"HORDE_ALLOW_UNSAFE_IP\"] = \"true\" if allow_unsafe_ip else \"false\"\n",
        "  os.environ[\"HORDE_MODELNAMES\"] = \",\".join(models_to_load)\n",
        "\n",
        "if mount_google_drive:\n",
        "  %cd /content/gdrive/MyDrive/nataili/\n",
        "else:\n",
        "  %cd /content/nataili/\n",
        "!python bridge.py $*"
      ],
      "metadata": {
        "cellView": "form",
        "id": "MUosNcNE3TPy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}