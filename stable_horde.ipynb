{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Use Google Drive (optional)\n",
        "#@markdown Models will be saved and loaded from your Google Drive.\n",
        "from google.colab import drive\n",
        "mount_google_drive = True\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "3qk09L_2q6J6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9Yrgnqzk2Wou"
      },
      "outputs": [],
      "source": [
        "#@markdown # Download repo\n",
        "update_repo = False #@param {type:\"boolean\"}\n",
        "\n",
        "if not \"mount_google_drive\" in locals():\n",
        "  mount_google_drive = False\n",
        "\n",
        "if mount_google_drive:\n",
        "  %cd /content/gdrive/MyDrive/\n",
        "else:\n",
        "  %cd /content/\n",
        "\n",
        "if update_repo:\n",
        "  %cd nataili/\n",
        "  !git pull\n",
        "else:\n",
        "  !git clone https://github.com/sd-webui/nataili.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json, requests, time, os\n",
        "from google.colab import drive\n",
        "from IPython.display import clear_output\n",
        "\n",
        "if not \"mount_google_drive\" in locals():\n",
        "  mount_google_drive = False\n",
        "\n",
        "#@markdown # Model Download/Load\n",
        "token = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Or\n",
        "Path_to_trained_model = \"\" #@param {type:\"string\"}\n",
        "#@markdown Insert the full path of your trained model (eg: /content/gdrive/MyDrive/zarathustra.ckpt) and it will automatically be placed in the right place, otherwise, leave it EMPTY (make sure there are no spaces in the path)\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "stable_diffusion_v1_5 = True #@param {type:\"boolean\"}\n",
        "#@markdown * Generalist AI image generating model. The baseline for all finetuned models.\n",
        "stable_diffusion_v1_4 = False #@param {type:\"boolean\"}\n",
        "#@markdown * Old version. Generalist AI image generating model. The baseline for all finetuned models.\n",
        "waifu_diffusion = False #@param {type:\"boolean\"}\n",
        "#@markdown * Anime styled generations.\n",
        "furry_epoch = False #@param {type:\"boolean\"}\n",
        "#@markdown * Furry styled generations.\n",
        "yiffy = False #@param {type:\"boolean\"}\n",
        "#@markdown * Furry styled generations.\n",
        "Zack3D = False #@param {type:\"boolean\"}\n",
        "#@markdown * Kink/NSFW oriented furry styled generations.\n",
        "trinart = False #@param {type:\"boolean\"}\n",
        "#@markdown * SFW Manga styled generations.\n",
        "\n",
        "if mount_google_drive:\n",
        "  %cd /content/gdrive/MyDrive/nataili/\n",
        "else:\n",
        "  %cd /content/nataili/\n",
        "\n",
        "!mkdir -p models/custom/\n",
        "!mkdir -p models/ldm/stable-diffusion-v1/\n",
        "\n",
        "models = json.load(open('./db.json'))\n",
        "dependencies = json.load(open('./db_dep.json'))\n",
        "remote_models = \"https://raw.githubusercontent.com/db0/nataili-model-reference/main/db.json\"\n",
        "remote_dependencies = \"https://raw.githubusercontent.com/db0/nataili-model-reference/main/db_dep.json\"\n",
        "try:\n",
        "  r = requests.get(remote_models)\n",
        "  models = r.json()\n",
        "  r = requests.get(remote_dependencies)\n",
        "  dependencies = dependencies\n",
        "except:\n",
        "  models = models\n",
        "  dependencies = dependencies\n",
        "\n",
        "def download_model(name):\n",
        "  if not name in models:\n",
        "    print(\"Model not found!\")\n",
        "\n",
        "  model = models[name]\n",
        "  download = model[\"config\"][\"download\"][0]\n",
        "\n",
        "  if 'file_url' in download:\n",
        "    download_url = download['file_url']\n",
        "    link = download_url.split(\"/\")\n",
        "    file_name = link[len(link) - 1]\n",
        "    if 'hf_auth' in download:\n",
        "      download_url = download_url.format(username=\"USER\", password=token)\n",
        "\n",
        "  if token == \"\" and \"hf_auth\" in download:\n",
        "    print('Huggingface token not supplied!')\n",
        "    exit()\n",
        "\n",
        "  model_destination = model[\"config\"][\"files\"][0][\"path\"]\n",
        "\n",
        "  !wget -O $model_destination $download_url\n",
        "  print(\"Downloaded model:\", name)\n",
        "\n",
        "if stable_diffusion_v1_5:\n",
        "  download_model(\"stable_diffusion\")\n",
        "if stable_diffusion_v1_4:\n",
        "  download_model(\"stable_diffusion_1.4\")\n",
        "if waifu_diffusion:\n",
        "  download_model(\"waifu_diffusion\")\n",
        "if furry_epoch:\n",
        "  download_model(\"waifu_diffusion\")\n",
        "if yiffy:\n",
        "  download_model(\"Yiffy\")\n",
        "if Zack3D:\n",
        "  download_model(\"Zack3D\")\n",
        "if trinart:\n",
        "  download_model(\"trinart\")\n",
        "\n",
        "if Path_to_trained_model != '':\n",
        "    if os.path.exists(str(Path_to_trained_model)):\n",
        "        clear_output()\n",
        "        !cp $Path_to_trained_model $required_path\n",
        "        if os.path.exists(required_path):\n",
        "            print('Model placed in the right directory')\n",
        "        else:\n",
        "            print('Something went wrong')\n",
        "    else:\n",
        "        print('Wrong path, use the colab file explorer to copy the path')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "sNOS6COYUQAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Install Python 3.8\n",
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.8\n",
        "\n",
        "#change alternatives\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.7 1\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 2\n",
        "\n",
        "#check python version\n",
        "!python --version\n",
        "\n",
        "# Install pip\n",
        "!sudo apt install python3-pip\n",
        "!python -m pip install --upgrade pip"
      ],
      "metadata": {
        "cellView": "form",
        "id": "U9H99XmOZ6Qu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Install dependencies\n",
        "\n",
        "if not \"mount_google_drive\" in locals():\n",
        "  mount_google_drive = False\n",
        "\n",
        "if mount_google_drive:\n",
        "  %cd /content/gdrive/MyDrive/nataili/\n",
        "else:\n",
        "  %cd /content/nataili\n",
        "\n",
        "!pip install -e .\n",
        "\n",
        "# See: https://github.com/CompVis/taming-transformers/issues/176\n",
        "# do not uncomment -e git+https://github.com/CompVis/taming-transformers.git@master#egg=taming-transformers\n",
        "!pip install invisible-watermark==0.1.5\n",
        "!pip install taming-transformers-rom1504==0.0.6  # required by ldm\n",
        "\n",
        "!pip install git+https://github.com/crowsonkb/k-diffusion.git\n",
        "\n",
        "# Dependencies required for Stable Diffusion UI\n",
        "!pip install pynvml==11.4.1\n",
        "!pip install omegaconf==2.2.3\n",
        "\n",
        "# Note: Jinja2 3.x major version required due to breaking changes found in markupsafe==2.1.1; 2.0.1 is incompatible with other upstream dependencies\n",
        "# see https://github.com/pallets/markupsafe/issues/304\n",
        "!pip install Jinja2==3.1.2  # Jinja2 is required by Gradio\n",
        "\n",
        "!pip install diffusers==0.4.1\n",
        "\n",
        "# Img2text\n",
        "!pip install fairscale==0.4.4\n",
        "!pip install timm==0.6.7\n",
        "!pip install tqdm==4.64.0\n",
        "\n",
        "# Other\n",
        "!pip install retry==0.9.2  # used by sd_utils\n",
        "!pip install python-slugify==6.1.2  # used by sd_utils\n",
        "!pip install piexif==1.1.3  # used by sd_utils\n",
        "\n",
        "!pip install accelerate==0.12.0\n",
        "!pip install albumentations==0.4.3\n",
        "!pip install einops==0.3.1\n",
        "!pip install facexlib>=0.2.3\n",
        "!pip install imageio-ffmpeg==0.4.2\n",
        "!pip install imageio==2.9.0\n",
        "!pip install kornia==0.6\n",
        "!pip install loguru\n",
        "!pip install opencv-python-headless==4.6.0.66\n",
        "!pip install open-clip-torch==2.0.2\n",
        "!pip install pandas==1.4.3\n",
        "!pip install pudb==2019.2\n",
        "!pip install pytorch-lightning==1.7.7\n",
        "!pip install realesrgan==0.3.0\n",
        "!pip install test-tube>=0.7.5\n",
        "!pip install timm==0.6.7\n",
        "!pip install torch-fidelity==0.3.0\n",
        "!pip install transformers==4.19.2 # do not change\n",
        "!pip install wget\n",
        "\n",
        "# Upscalers\n",
        "!pip install basicsr==1.4.2  # required by RealESRGAN\n",
        "!pip install gfpgan==1.3.8  # GFPGAN\n",
        "!pip install realesrgan==0.3.0  # RealESRGAN brings in GFPGAN as a requirement\n",
        "!pip install git+https://github.com/CompVis/latent-diffusion\n",
        "\n",
        "## for monocular depth estimation \n",
        "!pip install tensorflow==2.10.0"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Dk7dKkA3bKWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting worker info\n",
        "1. Rename `bridgeData_template.py` to `bridgeData.py`. \n",
        "2. Edit `bridgeData.py` and enter details such as the `horde_name` and `horde_api_key` you've received, so that you can receive Kudos.\n",
        "3. If you downloaded extra models other than 1.5, list it in `models_to_load`.\n",
        "**Note**: If you do not do this step, you will contribute anonymously."
      ],
      "metadata": {
        "id": "L4IfSgUTeNHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Start Stable Horde worker\n",
        "if not \"mount_google_drive\" in locals():\n",
        "  mount_google_drive = False\n",
        "\n",
        "if mount_google_drive:\n",
        "  %cd /content/gdrive/MyDrive/nataili/\n",
        "else:\n",
        "  %cd /content/nataili/\n",
        "!python bridge.py $*"
      ],
      "metadata": {
        "cellView": "form",
        "id": "MUosNcNE3TPy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}